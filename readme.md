# The Quest begins...

## Our Hero
![Hero_Cat](https://github.com/naomatheus/matt-rearc-quest/blob/main/images/IMG-2773.jpg)

## Our Developer Avatar
[Cloudquest Avatar](https://github.com/naomatheus/matt-rearc-quest/blob/main/images/cloudquest_character.png)

### Documentation

More detailed documentation is in the attached PDF [`rearc-quest-diagrams.pdf`](https://github.com/naomatheus/matt-rearc-quest/blob/images/diagrams/rearc-quest-diagrams.pdf). Along with two diagrams that did not show up in the PDF. [Initial Solution Architecture]() and [If-I-Had-More-Time Architecture]() Please visit this document link to see how I typically break down and document cloud architecture problems/solutions. This challenge was so good that I will definitely be coming back to the work I did here. I find that coming back to a Confluence page with a high level diagram is a lot easier than sifting through IaC code alone.

### Notes Upon completion

- Proof of completion is in `/completion-screenshots` directory
    - These are screenshots of visiting the application's test URLs on my Mac M1.

- The folder structure featured here is not necessarily the one I would use on the job. I actually did the work of applying this infrastructure in a separate directory that houses some of my other cloud work, and then copied the relevant files into this "presentation repository."

- Global yaml files used by Terragrunt to import cloud configurations are not included in this repository.

- There may be some edits to the Javascript 000.js file. I was having a little trouble with permissions on the server, so I added a test route and added `uid` parameters to a couple of routes to see if that would help resolve the issue.

- I will deactivate the server, and you won't be able to view the live links unless requested.

### Given more time, I would improve... 

- In a normal scenario, I would find a more secure and automated way to load application files onto a remote host or remote container. Such as...
    - Pulling environment variables from a file in a KMS encrypted S3 bucket. 
    - Using boto3, codecommit client, or ECR container repository to access files or a container image.
    - In this case, I simply used Visual Studio Code remote to load the `quest` files onto the remote machine host from my local host.

- I also would have set up communication between a private subnet and public subnet, and placed servers/containers, databases in the private subnet(s) so they do not have public IPs from the internet

- This solution excludes an kind of autoscaling that would take advantage of AWS auto-scaling groups for EC2 instances or auto-scaling capabilities in Elastic Container Service (ECS).
    - I would implement an EC2 ASG (more complicated)
    - OR
    - I would deploy this solution with a container service such as ECS.

- I'm a devoted fan of ECS and Fargate, and given more time this would be my approach to re-deploying or deploying an improved version of this application. 
    - I would build the application locally, uploaded it to ECR, and provision an ECS Cluster, Service, and Task to pick up the app and run with AWS Fargate.

- I enjoy the relative simplicity of Build/Rebuild triggers that can be issued to the ECS service from a CI/CD Pipeline tool such as Gitlab.
    - I would create a Gitlab CI/CD repository (or Github Actions) to hold the project code, Dockerfile, and CI/CD Yaml config. 
    - In the CI/CD instructions, the steps would be roughly something like this upon pushes to the repo...
    
```
# define vars
variables:

  REPOSITORY_URI: $REPOSITORY_URI 
  # Vars such as the ECR repository we're workig with
  # The value of the vars is injected into the CI/CD environment
  ...

# AWS Vars
  DEFAULT_ACCESS_KEY: $DEFAULT_ACCESS_KEY
  ...

  # Dockerfile arguments
  DB_HOST: $DB_HOST
  ...

before_script:
# set service role AWS credentials and login to the ECR repo

    - $(aws ecr get-login --no-include-email --region "${AWS_DEFAULT_REGION}")
    ...

build:
  stage: build
  script:
  Build docker image
  ...

# deploy, register the new task definition, update service to run with new task definition
deploy:
  stage: deploy
  script:
    1. Get the current ECS task definition
    2. Use JQ to be a ninja and get variables from JSON to create an new task definition that increments the image version and matches the IMAGE tag generated by the build
    3. `aws ecs register new task defition`...
    4. `aws ecs update the service to use the automatically built image`
    5. We did this from local by pushing to Gitlab.
    ...

post-build:
  stage: post-build
  script:
    # delete docker config records because some values of could potentially be exposed in docker logs
    - rm -f /root/.docker/config.json

```

- In between prepping for interviews and coding challengs I spent overall about 6 to 7 hours on the Quest. I really liked this challenge from the first time I read about it after an informational with a recruiter. I took the opportunity to use this challenge to prepare a cloud environment that I can reuse for personal projects and other development experiments. The challenge did take me a bit longer because of that.

- The first 2 - 3 hours of the Quest, I set up my VPC, "troubleshot" networking issues and ssh access, and rewrote my terraform modules to use terragrunt instead of just terraform.

- Networking is not my strong suit, and this challenge was a great learning tool for me. I actually know more about VPC Networking for EC2 than I did a few days ago. That's the sign of an awesome and applicable code challenge, Kudos.

- You probably will notice that the web server in my setup is in a public subnet. I understand that this is not ideal. I plan to update this when I get more time.

- The Dockerfile command to handles permission issues in the application's binary files is not fully resolved. If I had more time I would look into this. It may be that in the Dockerfile some more specific user permissions should be set up in advance, or the `chmod` should be issued with as sudo.

#### Finally, 

- I look forward to your code review and please let me know if you have any further questions.